# report1

## 有监督分类学习

### 代码运行

- 运行main.py
- 在Method中输入要采用的算法【"knn" or "svm" or "other"】

### 算法思想

#### 1. 数据预处理

- class DataSet()：为数据集建立的类

- 主要方法：preprocessing

  - 从sourcefile中读取源数据

  - 将训练数据和标签分离，并对训练数据进行编码（labelEncoder.fit_transform），将标签二值化

    **注：**

    - **对于数字类型的列不要进行重新编码，只需将str型转化为数字类型即可，否则会破坏数据本身的数字特征**
    - **对于使用G1、G2和不使用G1、G2的情况，会得到不同列数的数据集，由参数usingG控制**
    - **SVM的标签要求模长为1，故负例标签需标-1**

  - 数据按行随机化（np.random.shuffle），然后按照scale比例划分训练集和数据集

#### 2. 分类算法

- **KNN**：

  分类时对测试集的每个vector，计算它到数据集中的每个点的距离（这里使用欧氏距离），然后选取距离最近的K个点，统计这K个点中的标签，vector属于K个点中数目较多的标签类别

- **SVM**：

  - **核函数**：选用高斯核函数，因为高斯核函数不受线性约束，且具有较强的适应性，能够在各种数据分布下呈现较好的分类性能

  - **训练目标**：训练alpha、b使得损失函数（约束问题的对偶问题目标函数）尽可能小

  - **算法核心过程**：两层循环

    外层循环选择alpha1：选择在训练集中违反KKT条件最严重的样本点

    内层循环选择alpha2：尽可能使目标函数变化最大，即$|E_1-E_2|_{max}$

    计算alpha2的上下界H、L

    依次求新的alpha2、alpha1、b并更新

    <u>更新误差函数列表E</u>

    判断迭代条件，即是否达到epsilon精度

  - **优化点：上述算法中，建立辅助列表E，存储每个向量对应的误差函数，这样在每次需要求误差时可以直接访问列表得到，且只需在更新alpha1、alpha2、b后对相应的两项误差函数进行更新，这样可以避免每次迭代计算误差时$O(n^3)$的时间开销，大幅优化时间性能**

- **LogisticRegression**：
  - 训练目标：权重向量weight
  - 使用sigmoid函数作为分类反馈函数，将数据集与权重向量相乘后用sigmoid函数映射得到分类结果，与标签作差得到误差，每次选取误差的梯度方向进行更新

#### 3. 评估函数

用测试集的label与predictlabel统计TP, FP, FN, TN，并计算准确率、召回率和F1值

### 性能测试和分析

|                                   |          |   mat.csv   |   por.csv   |
| :-------------------------------: | :------: | :---------: | :---------: |
|       **KNN with G score**        | 准确率 P |   90.90%    |   91.53%    |
|                                   | 召回率 R |   92.10%    |   97.59%    |
|                                   | F1 score | 0.915 [K=5] | 0.945 [K=7] |
|      **KNN without G score**      | 准确率 P |   76.00%    |   83.50%    |
|                                   | 召回率 R |   91.57%    |    100%     |
|                                   | F1 score | 0.831 [K=9] | 0.910 [K=9] |
|       **SVM with G score**        | 准确率 P |    100%     |   89.13%    |
| (C=100, sigma=5, epsilon=0.00001) | 召回率 R |   75.95%    |    100%     |
|                                   | F1 score |    0.863    |    0.943    |
|      **SVM without G score**      | 准确率 P |   71.57%    |   90.42%    |
|                                   | 召回率 R |   90.12%    |   86.78%    |
|                                   | F1 score |    0.798    |    0.886    |
|        **LR with G score**        | 准确率 P |   70.09%    |   84.02%    |
|                                   | 召回率 R |    100%     |    100%     |
|                                   | F1 score |    0.824    |    0.913    |
|      **LR without G score**       | 准确率 P |   62.39%    |   82.99%    |
|                                   | 召回率 R |    100%     |    100%     |
|                                   | F1 score |    0.768    |    0.907    |

##### 结果分析：

- KNN的时间性能比SVM稍好一些，但由于KNN没有训练权重而是对测试集的每个样本都需要遍历数据集，故当数据规模很大时时间性能会下降很多
- 由于在数据预处理时用shuffle随机化数据，故每次运行时的数据集划分都不太一样，导致每次的实验结果不同，但从实验过程中来看，SVM受数据集的影响更大，性能波动比较大。从算法角度分析，SVM由于需要训练权重，故对数据集的要求更高
- 上述表中结果中，KNN的参数K基本取了调参后最好的情况，总体来看其分类性能比SVM更好，但由于SVM的性能波动太大，且参数比较多，故我选用的参数不一定是调参的最佳结果，此结论仅具有参考意义
- LR算法的稳定性比较好，也有着不错的性能，但是总会出现预测全部为1的情况

